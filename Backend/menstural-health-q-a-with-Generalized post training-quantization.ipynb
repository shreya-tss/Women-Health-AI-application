{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install torch\n! pip install transformers\n! pip install langchain_community\n! pip install langchain\n! pip install langchain-huggingface\n! pip install langchain_experimental\n! pip install langchain_chroma\n! pip install langchainhub\n! pip install unstructured","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install flask flask-cors pyngrok","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!ngrok config add-authtoken 2u8201NvKgcEzWonKQNTCyso6fO_3vyZYXHMXaaiYAq9HvPZX","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.document_loaders import UnstructuredURLLoader\n\nurls = [\n    'https://en.wikipedia.org/wiki/Menstruation', 'https://kidshealth.org/en/teens/menstruation.html',\n    'https://www.nhs.uk/conditions/periods/', 'https://my.clevelandclinic.org/health/articles/10132-menstrual-cycle',\n    'https://www.thewomens.org.au/health-information/periods/periods-overview/about-periods',\n    'https://www.mayoclinic.org/healthy-lifestyle/womens-health/in-depth/menstrual-cycle/art-20047186',\n    'https://www.mayoclinic.org/diseases-conditions/menopause/symptoms-causes/syc-20353397',\n    'https://en.wikipedia.org/wiki/Menopause', 'https://www.nia.nih.gov/health/menopause/what-menopause',\n    'https://en.wikipedia.org/wiki/Ovulation', \n    'https://www.westsuburbanmc.com/the-role-of-hormones-in-the-menstrual-cycle','https://www.wikihow.com/Enjoy-Periods','https://www.healthline.com/health/womens-health/what-to-eat-during-period','https://www.webmd.com/women/ss/slideshow-women-superfoods', 'https://my.clevelandclinic.org/health/articles/23439-ovulation', \"https://en.wikipedia.org/wiki/Pregnancy\", \"https://my.clevelandclinic.org/health/articles/pregnancy\", \"https://www.nhs.uk/start-for-life/pregnancy/\", \"https://my.clevelandclinic.org/health/articles/9677-fetal-positions-for-birth\"\n]\nloader = UnstructuredURLLoader(urls=urls)\ndata = loader.load()\n\nprint(data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install langchain langchain_chroma sentence-transformers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.document_loaders import UnstructuredURLLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_chroma import Chroma\nfrom sentence_transformers import CrossEncoder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Text splitting ","metadata":{}},{"cell_type":"code","source":"\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\ndocs = text_splitter.split_documents(data)\nprint(\"Total number of documents:\", len(docs))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Embedding","metadata":{}},{"cell_type":"code","source":"embedding_model = HuggingFaceEmbeddings()\nvectorstore = Chroma.from_documents(documents=docs, embedding=embedding_model)\nretriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":10})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cross-Encoder Re-Ranking","metadata":{}},{"cell_type":"code","source":"reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n\ndef cross_encoder_rerank(query, retrieved_docs, top_n=3):\n    # Prepare query-document pairs\n    pairs = [(query, doc.page_content) for doc in retrieved_docs]\n\n    # Score pairs using the cross-encoder\n    scores = reranker.predict(pairs)\n\n    # Sort by score (higher is better)\n    reranked_docs = sorted(zip(retrieved_docs, scores), key=lambda x: x[1], reverse=True)\n\n    # Return the top-n documents\n    return [doc for doc, _ in reranked_docs[:top_n]]\n\n# Retrieve and re-rank\nquery = \"What is menstruation?\"\nretrieved_docs = retriever.invoke(query)\nreranked_docs = cross_encoder_rerank(query, retrieved_docs)\n\n# Display results\nfor i, doc in enumerate(reranked_docs):\n    print(f\"\\n### Document {i+1} ###\\n\")\n    print(doc.page_content[:500], \"...\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## RAG Pipeline","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain_huggingface import HuggingFacePipeline\nfrom langchain_core.output_parsers import StrOutputParser\nfrom transformers import pipeline\nimport torch\nmodel_id = \"microsoft/phi-2\"\n\ntext_generation_pipeline = pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    max_new_tokens=200,\n    device=0,\n    return_full_text=False,\n    do_sample=False,\n    eos_token_id=50256\n)\n\nllm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n\n# Structured prompt to enforce concise Q&A format\nprompt_template = \"\"\"\nYou are an expert on menstruation. Based on the following context, answer the question accurately and concisely. Do NOT include extra information. Do NOT generate unrelated texts.\n\n\nContext:\n{context}\n\nQuestion:\n{question}\n\nAnswer:\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables=[\"context\", \"question\"],\n    template=prompt_template,\n)\n\n# Create LLM chain\nllm_chain = prompt | llm | StrOutputParser()\n\n# RAG Pipeline Function\ndef retrieve_and_answer(question):\n    # Retrieve top documents from Chroma\n    retrieved_docs = retriever.invoke(question)\n    reranked_docs = cross_encoder_rerank(question, retrieved_docs)\n    context = \"\\n\".join([doc.page_content for doc in reranked_docs])\n\n    # Invoke LLM\n    response = llm_chain.invoke({\"context\": context, \"question\": question})\n\n    return response\n\ncontext_1 = \"\"\"\nMenstruation is the shedding of the uterine lining when pregnancy does not occur. It is regulated by estrogen and progesterone.\n\"\"\"\nquestion_1 = \"How do I relive menstrual cramps?\"\n\ncontext_2 = \"\"\"\nMenstrual pain (dysmenorrhea) is caused by prostaglandins triggering uterine contractions. Conditions like endometriosis can worsen it.\n\"\"\"\nquestion_2 = \"Why do some people experience pain during menstruation?\"\n\n# Run the chain with Menstruation-related input\nresponse_1 = llm_chain.invoke({\"context\": context_1, \"question\": question_1})\nresponse_2 = llm_chain.invoke({\"context\": context_2, \"question\": question_2})\n\n# Print Outputs\nprint(\"Answer 1:\", response_1)\nprint(\"Answer 2:\", response_2)\n'''\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers peft bitsandbytes accelerate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install git+https://github.com/PanQiWei/AutoGPTQ.git\n!pip install optimum","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install --upgrade pip\n#!pip install git+https://github.com/PanQiWei/AutoGPTQ.git\n#!pip install optimum","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade transformers accelerate\n!pip install --upgrade optimum auto-gptq","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip uninstall transformers -y\n#!pip uninstall huggingface-hub -y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_core.output_parsers import StrOutputParser","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.prompts import PromptTemplate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install auto-gptq --quiet  # Run only once","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(torch.cuda.is_available())  # should be True\nprint(torch.cuda.device_count())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade transformers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -y transformers huggingface_hub\n!pip install transformers==4.37.2 huggingface_hub","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install -U transformers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_huggingface import HuggingFacePipeline\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nimport torch\n\n# QLoRA model - use a quantized fine-tuned model\nmodel_id = \"TheBloke/phi-2-GPTQ\"  # Example QLoRA model (change to your fine-tuned one)\n\n# Load model and tokenizer (QLoRA is quantized, so use `AutoModelForCausalLM`)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n    low_cpu_mem_usage=True,\n)\n\n# Text generation pipeline\ntext_generation_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    return_full_text=False,\n    max_new_tokens=200,\n    do_sample=False,\n    eos_token_id=50256,\n)\n\n# Wrap pipeline into LangChain\nllm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n\n# Prompt template remains unchanged\nprompt_template = \"\"\"\n### Instruction:\nExplain what causes menstruation in humans in a concise and factual way.\n\n### Response:\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables=[\"context\", \"question\"],\n    template=prompt_template,\n)\n'''\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain.llms import HuggingFacePipeline\nfrom auto_gptq import AutoGPTQForCausalLM\nimport torch\nmodel_id = \"theBloke/Mistral-7B-Instruct-v0.1-GPTQ\"  # or the GPTQ version like 'TheBloke/phi-2-GPTQ'\n# Load model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoGPTQForCausalLM.from_quantized(\n    model_id,\n    device_map={\"\": 0},  # Your T4 GPU\n    use_safetensors=True,\n    trust_remote_code=True,\n    torch_dtype=torch.float16,\n    revision=\"main\"\n)\n# Better pipeline config\ntext_gen_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=256,\n    do_sample=True,\n    temperature=0.8,\n    top_p=0.95,\n    repetition_penalty=1.1,\n    return_full_text=False\n)\n# Wrap with LangChain\nllm = HuggingFacePipeline(pipeline=text_gen_pipeline)\n# Use instruction-style prompt\n# Prompt template remains unchanged\nprompt_template = \"\"\"\nYou are an expert on menstruation. Based on the following context, answer the question accurately and concisely. Do NOT include extra information. Do NOT generate unrelated texts.\nContext:\n{context}\nQuestion:\n{question}\nAnswer:\n\"\"\"\nprompt = PromptTemplate(\n    input_variables=[\"context\", \"question\"],\n    template=prompt_template,\n)\n# LangChain LLM chain setup\nllm_chain = prompt | llm | StrOutputParser()\ndef retrieve_and_answer(question):\n    # Retrieve top documents from Chroma\n    retrieved_docs = retriever.invoke(question)\n    reranked_docs = cross_encoder_rerank(question, retrieved_docs)\n    context = \"\\n\".join([doc.page_content for doc in reranked_docs])\n    # Invoke LLM\n    response = llm_chain.invoke({\"context\": context, \"question\": question})\n    return response\ncontext_1 = \"\"\"\nMenstruation is the shedding of the uterine lining when pregnancy does not occur. It is regulated by estrogen and progesterone.\n\"\"\"\nquestion_1 = \"How do I relive menstrual cramps?\"\ncontext_2 = \"\"\"\nMenstrual pain (dysmenorrhea) is caused by prostaglandins triggering uterine contractions. Conditions like endometriosis can worsen it.\n\"\"\"\nquestion_2 = \"Why do some people experience pain during menstruation?\"\n# Run the chain with Menstruation-related input\nresponse_1 = llm_chain.invoke({\"context\": context_1, \"question\": question_1})\nresponse_2 = llm_chain.invoke({\"context\": context_2, \"question\": question_2})\n# Print Outputs\nprint(\"Answer 1:\", response_1)\nprint(\"Answer 2:\", response_2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_2 = \"\"\"\nMenstrual pain (dysmenorrhea) is caused by prostaglandins triggering uterine contractions. Conditions like endometriosis can worsen it.\n\"\"\"\nquestion_2 = \"How do I insert a menstrual cup?\"\n\nresponse_3 = llm_chain.invoke({\"context\": context_2, \"question\": question_2})\nprint(\"Answer 2:\", response_3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_4 = \"\"\"\nMenstrual pain (dysmenorrhea) is caused by prostaglandins triggering uterine contractions. Conditions like endometriosis can worsen it.\n\"\"\"\nquestion_4 = \"Why do some pregnant people experience back pain in the second trimester?\"\n\nresponse_4 = llm_chain.invoke({\"context\": context_4, \"question\": question_4})\nprint(\"Answer 2:\", response_4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_4 = \"\"\"\nMenstrual pain (dysmenorrhea) is caused by prostaglandins triggering uterine contractions. Conditions like endometriosis can worsen it.\n\"\"\"\nquestion_4 = \"What are the symptoms of pre menopause symptoms?\"\n\nresponse_4 = llm_chain.invoke({\"context\": context_4, \"question\": question_4})\nprint(\"Answer 2:\", response_4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_5 = \"\"\"\nMenstrual pain (dysmenorrhea) is caused by prostaglandins triggering uterine contractions. Conditions like endometriosis can worsen it.\n\"\"\"\nquestion_5 = \"How to reduce hormonal acne?\"\n\nresponse_5 = llm_chain.invoke({\"context\": context_5, \"question\": question_5})\nprint(\"Answer 2:\", response_5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context_5 = \"\"\"\nMenstrual pain (dysmenorrhea) is caused by prostaglandins triggering uterine contractions. Conditions like endometriosis can worsen it.\n\"\"\"\nquestion_5 = \"What are some premenopause symptoms?\"\n\nresponse_5 = llm_chain.invoke({\"context\": context_5, \"question\": question_5})\nprint(\"Answer 2:\", response_5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\nfrom pyngrok import ngrok\n\napp = Flask(__name__)\nCORS(app, resources={r\"/*\": {\"origins\": \"*\"}}, supports_credentials=True)\n\n# Handle preflight requests\n@app.before_request\ndef handle_preflight():\n    if request.method == \"OPTIONS\":\n        return jsonify({\"message\": \"Preflight OK\"}), 200\n\n@app.route('/ask', methods=['POST'])\ndef ask():\n    try:\n        data = request.get_json()\n        question = data.get(\"question\")\n\n        if not question:\n            return jsonify({\"error\": \"No question provided\"}), 400\n\n        # Placeholder context\n        context = \"\"\"\n        Menstruation is the shedding of the uterine lining when pregnancy does not occur.\n        It is regulated by estrogen and progesterone.\n        \"\"\"\n\n        # Get response from LLM\n        response = llm_chain.invoke({\"context\": context, \"question\": question, \"stop\": [\"\\n\\n\"]})\n\n        return jsonify({\"answer\": response}), 200\n\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\n# Start ngrok tunnel\npublic_url = ngrok.connect(5000).public_url\nprint(f\"Public API URL: {public_url}\")\n\n# Run Flask server\napp.run(port=5000)\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context = \"Menstruation is regulated by hormones like estrogen and progesterone, which control the shedding of the uterine lining.\"\nquestion = \"Which are the other mammals that mensturate?\"\n\noutput = llm_chain.invoke({\"context\": context, \"question\": question,\"stop\": [\"\\n\\n\"] })\nprint(output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context = \"Menstruation is regulated by hormones like estrogen and progesterone, which control the shedding of the uterine lining.\"\nquestion=\"Recommend some foods to eat during pregnancy?\"\noutput = llm_chain.invoke({\"context\": context, \"question\": question,\"stop\": [\"\\n\\n\"] })\nprint(output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context = \"Menstruation is regulated by hormones like estrogen and progesterone, which control the shedding of the uterine lining.\"\nquestion=\"What is cervical cancer and how can I be more aware of it?\"\noutput = llm_chain.invoke({\"context\": context, \"question\": question,\"stop\": [\"\\n\\n\"] })\nprint(output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context = \"Menstruation is regulated by hormones like estrogen and progesterone, which control the shedding of the uterine lining.\"\nquestion=\"Can hormone replacement therapy (HRT) relieve menopausal symptoms?\"\noutput = llm_chain.invoke({\"context\": context, \"question\": question,\"stop\": [\"\\n\\n\"] })\nprint(output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context = \"Menstruation is regulated by hormones like estrogen and progesterone, which control the shedding of the uterine lining.\"\nquestion=\"how to get rid of acne?\"\noutput = llm_chain.invoke({\"context\": context, \"question\": question, \"stop\": [\"\\n\\n\"]})\nprint(output)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef evaluate_ranking_metrics(query, retrieved_docs, relevant_docs, top_k=3):\n    reranked_docs = cross_encoder_rerank(query, retrieved_docs, top_n=top_k)\n\n    # Extract content for evaluation\n    reranked_texts = [doc.page_content for doc in reranked_docs]\n\n    # Mean Reciprocal Rank (MRR)\n    mrr = 0\n    for idx, doc in enumerate(reranked_texts):\n        if doc in relevant_docs:\n            mrr = 1 / (idx + 1)\n            break\n\n    # Precision@k\n    precision = sum(1 for doc in reranked_texts if doc in relevant_docs) / top_k\n\n    # Recall@k\n    recall = sum(1 for doc in reranked_texts if doc in relevant_docs) / len(relevant_docs)\n\n    print(f\"MRR: {mrr:.4f}, Precision@{top_k}: {precision:.4f}, Recall@{top_k}: {recall:.4f}\")\n    return mrr, precision, recall\n\n# BLEU Score Calculation\ndef evaluate_bleu(generated_answer, reference_answer):\n    reference_tokens = [nltk.word_tokenize(reference_answer)]\n    generated_tokens = nltk.word_tokenize(generated_answer)\n\n    bleu_score = sentence_bleu(reference_tokens, generated_tokens)\n\n    print(f\"BLEU Score: {bleu_score:.4f}\")\n    return bleu_score\n\n# Example Conversation\nanswer = retrieve_and_answer(\"Why do some people experience pain during menstruation?\")\nevaluate_bleu(answer, \"Menstrual cramps are caused by uterine contractions triggered by prostaglandins.\")\n\nanswer = retrieve_and_answer(\"How can they reduce the pain?\")\nevaluate_bleu(answer, \"Pain relief can be achieved through medications, heat therapy, and lifestyle changes.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# BLEU Score Calculation\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\ndef evaluate_ranking_metrics(query, retrieved_docs, relevant_docs, top_k=3):\n    reranked_docs = cross_encoder_rerank(query, retrieved_docs, top_n=top_k)\n\n    # Extract content for evaluation\n    reranked_texts = [doc.page_content for doc in reranked_docs]\n\n    # Mean Reciprocal Rank (MRR)\n    mrr = 0\n    for idx, doc in enumerate(reranked_texts):\n        if doc in relevant_docs:\n            mrr = 1 / (idx + 1)\n            break\n\n    # Precision@k\n    precision = sum(1 for doc in reranked_texts if doc in relevant_docs) / top_k\n\n    # Recall@k\n    recall = sum(1 for doc in reranked_texts if doc in relevant_docs) / len(relevant_docs)\n\n    print(f\"MRR: {mrr:.4f}, Precision@{top_k}: {precision:.4f}, Recall@{top_k}: {recall:.4f}\")\n    return mrr, precision, recall\n\ndef evaluate_bleu(generated_answer, reference_answer):\n    reference_tokens = [nltk.word_tokenize(reference_answer)]\n    generated_tokens = nltk.word_tokenize(generated_answer)\n\n    # Apply smoothing\n    smoothie = SmoothingFunction().method4\n    bleu_score = sentence_bleu(reference_tokens, generated_tokens, smoothing_function=smoothie)\n\n    print(f\"BLEU Score (smoothed): {bleu_score:.4f}\")\n    return bleu_score\n\n# Example Conversation\nanswer = retrieve_and_answer(\"Why do some people experience pain during menstruation?\")\nevaluate_bleu(answer, \"Menstrual cramps are caused by uterine contractions triggered by prostaglandins.\")\n\nanswer = retrieve_and_answer(\"How can they reduce the pain?\")\nevaluate_bleu(answer, \"Pain relief can be achieved through medications, heat therapy, and lifestyle changes.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom difflib import SequenceMatcher\n\ndef similar(a, b):\n    return SequenceMatcher(None, a, b).ratio()\n\ndef evaluate_ranking_metrics_debug(query, retrieved_docs, relevant_docs, top_k=3):\n    reranked_docs = cross_encoder_rerank(query, retrieved_docs, top_n=top_k)\n\n    # Extract content for evaluation\n    reranked_texts = [doc.page_content.strip().lower() for doc in reranked_docs]\n    relevant_texts = [doc.strip().lower() for doc in relevant_docs]\n\n    # Debugging: Print retrieved vs relevant documents\n    print(\"\\n--- Debug: Retrieved Docs ---\")\n    for doc in reranked_texts:\n        print(f\"Retrieved: {doc}\")\n\n    print(\"\\n--- Debug: Relevant Docs ---\")\n    for doc in relevant_texts:\n        print(f\"Relevant: {doc}\")\n\n    # Print similarity scores\n    print(\"\\n--- Debug: Similarity Scores ---\")\n    for ret_doc in reranked_texts:\n        for rel_doc in relevant_texts:\n            score = similar(ret_doc, rel_doc)\n            print(f\"Similarity({ret_doc[:50]}..., {rel_doc[:50]}...) = {score:.4f}\")\n\n    # Adjust threshold if needed\n    threshold = 0.12  # Try lowering if needed\n\n    # Mean Reciprocal Rank (MRR)\n    mrr = 0\n    for idx, doc in enumerate(reranked_texts):\n        if any(similar(doc, rel) > threshold for rel in relevant_texts):\n            mrr = 1 / (idx + 1)\n            break\n\n    # Precision@k\n    precision = sum(1 for doc in reranked_texts if any(similar(doc, rel) > threshold for rel in relevant_texts)) / top_k\n\n    # Recall@k\n    recall = sum(1 for doc in reranked_texts if any(similar(doc, rel) > threshold for rel in relevant_texts)) / len(relevant_texts)\n\n    print(f\"\\nMRR: {mrr:.4f}, Precision@{top_k}: {precision:.4f}, Recall@{top_k}: {recall:.4f}\")\n    return mrr, precision, recall\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\n\nmodel = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")  # Small, fast embedding model\n\ndef evaluate_ranking_metrics_3(query, retrieved_docs, relevant_docs, top_k=3):\n    reranked_docs = cross_encoder_rerank(query, retrieved_docs, top_n=top_k)\n\n    # Extract content for evaluation\n    reranked_texts = [doc.page_content.strip().lower() for doc in reranked_docs]\n    relevant_texts = [doc.strip().lower() for doc in relevant_docs]\n\n    # Encode the texts as vectors\n    retrieved_embeddings = model.encode(reranked_texts, convert_to_tensor=True)\n    relevant_embeddings = model.encode(relevant_texts, convert_to_tensor=True)\n\n    # Compute cosine similarity\n    similarity_scores = util.pytorch_cos_sim(retrieved_embeddings, relevant_embeddings)\n\n    # Compute MRR\n    mrr = 0\n    for idx in range(len(reranked_texts)):\n        if max(similarity_scores[idx]) > 0.7:  # 70% similarity threshold\n            mrr = 1 / (idx + 1)\n            break\n\n    # Compute Precision@k\n    precision = sum(1 for idx in range(len(reranked_texts)) if max(similarity_scores[idx]) > 0.7) / top_k\n\n    # Compute Recall@k\n    recall = sum(1 for idx in range(len(reranked_texts)) if max(similarity_scores[idx]) > 0.7) / len(relevant_texts)\n\n    print(f\"\\nMRR: {mrr:.4f}, Precision@{top_k}: {precision:.4f}, Recall@{top_k}: {recall:.4f}\")\n    return mrr, precision, recall","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\ndef retrieve_documents(question):\n    \"\"\"Retrieve and rerank documents without invoking the LLM.\"\"\"\n    retrieved_docs = retriever.vectorstore.similarity_search(question, k=10)\n    reranked_docs = cross_encoder_rerank(question, retrieved_docs)  # Rerank with cross-encoder\n    return reranked_docs  # Return only the documents, not the LLM response\n\n# Test Setup\nquery = \"What causes period pain?\"\n\n# Get retrieved and reranked documents (BEFORE calling LLM)\nretrieved_docs = retrieve_documents(query)\n\n# Define relevant documents (ground truth)\nrelevant_docs = [\n    \"Menstrual pain is caused by uterine contractions due to prostaglandins.\",\n    \"Some women feel cramps due to high levels of inflammation.\"\n]\n\n# Run the ranking evaluation\nevaluate_ranking_metrics_2(query, retrieved_docs, relevant_docs)\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\ndef retrieve_documents(question):\n    \"\"\"Retrieve and rerank documents without invoking the LLM.\"\"\"\n    retrieved_docs = retriever.vectorstore.similarity_search(question, k=10)\n    reranked_docs = cross_encoder_rerank(question, retrieved_docs)  # Rerank with cross-encoder\n    return reranked_docs  # Return only the documents, not the LLM response\n\n# Test Setup\nquery = \"What are common symptoms of PMS?\"\n\n# Get retrieved and reranked documents (BEFORE calling LLM)\nretrieved_docs = retrieve_documents(query)\n\n# Define relevant documents (ground truth)\nrelevant_docs = [\n    \"Premenstrual syndrome (PMS) can cause mood swings, bloating, and fatigue.\",\n    \"Common PMS symptoms include headaches, breast tenderness, and irritability.\",\n    \"Many people experience cramps, food cravings, and difficulty sleeping before their period.\"\n]\n\n# Run the ranking evaluation\nevaluate_ranking_metrics_debug(query, retrieved_docs, relevant_docs)\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def retrieve_documents(question):\n    \"\"\"Retrieve and rerank documents without invoking the LLM.\"\"\"\n    retrieved_docs = retriever.vectorstore.similarity_search(question, k=10)\n    reranked_docs = cross_encoder_rerank(question, retrieved_docs)  # Rerank with cross-encoder\n    return reranked_docs  # Return only the documents, not the LLM response\n\n# Test Setup\nquery = \"What are common symptoms of PMS?\"\n\n# Get retrieved and reranked documents (BEFORE calling LLM)\nretrieved_docs = retrieve_documents(query)\n\n# Define relevant documents (ground truth)\nrelevant_docs = [\n    \"Premenstrual syndrome (PMS) can cause mood swings, bloating, and fatigue.\",\n    \"Common PMS symptoms include headaches, breast tenderness, and irritability.\",\n    \"Many people experience cramps, food cravings, and difficulty sleeping before their period.\"\n]\n\n# Run the ranking evaluation\nevaluate_ranking_metrics_3(query, retrieved_docs, relevant_docs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def retrieve_documents(question):\n    \"\"\"Retrieve and rerank documents without invoking the LLM.\"\"\"\n    retrieved_docs = retriever.vectorstore.similarity_search(question, k=10)\n    reranked_docs = cross_encoder_rerank(question, retrieved_docs)  # Rerank with cross-encoder\n    return reranked_docs  # Return only the documents, not the LLM response\n\n# Test Setup\nquery = \"What foods help with period cramps?\"\n\n# Get retrieved and reranked documents (BEFORE calling LLM)\nretrieved_docs = retrieve_documents(query)\n\n# Define relevant documents (ground truth)\nrelevant_docs = [\n    \"Foods rich in magnesium, like bananas and spinach, can help relax muscles and reduce cramps.\",\n    \"Drinking ginger tea may help relieve menstrual pain due to its anti-inflammatory properties.\",\n    \"Dark chocolate contains antioxidants that can help reduce period discomfort.\"\n]\n\n# Run the ranking evaluation\nevaluate_ranking_metrics_3(query, retrieved_docs, relevant_docs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nprint(torch.cuda.memory_allocated() / 1e6, \"MB\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pynvml import *\nnvmlInit()\nhandle = nvmlDeviceGetHandleByIndex(0)\npower = nvmlDeviceGetPowerUsage(handle) / 1000  # mW to W\nprint(f\"Power: {power} Watts\")\nnvmlShutdown()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\ncontext = \"Menstruation is regulated by hormones like estrogen and progesterone, which control the shedding of the uterine lining.\"\nquestion = \"How to reduce hormonal acne?\"\n\n# Start timer\nstart_time = time.time()\n\n# Model inference\noutput = llm_chain.invoke({\"context\": context, \"question\": question, \"stop\": [\"\\n\\n\"]})\n\n# End timer\nend_time = time.time()\n\n# Calculate inference time\ninference_time = end_time - start_time\nprint(\"Output:\", output)\nprint(f\"Inference time: {inference_time:.4f} seconds\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nfrom pynvml import *\n\n# Initialize NVML for GPU power usage\nnvmlInit()\nhandle = nvmlDeviceGetHandleByIndex(0)\n\n# Your test prompts\nquestions = [\n    \"how to get rid of hormonal acne?\",\n    \"what are symptoms of menstruation?\",\n    \"can periods affect mood?\",\n    \"how to relieve menstrual cramps?\",\n    \"why do periods happen?\"\n]\n\n# Dummy context (you can make this dynamic)\ncontext = \"Menstrual pain (dysmenorrhea) is caused by prostaglandins triggering uterine contractions. Conditions like endometriosis can worsen it.\"\n\n# This will store benchmarking results\ndef benchmark_model(llm_chain, model_name):\n    times, powers = [], []\n\n    print(f\"\\n--- Benchmarking {model_name} ---\")\n    for q in questions:\n        power_start = nvmlDeviceGetPowerUsage(handle) / 1000  # in watts\n\n        start = time.time()\n        output = llm_chain.invoke({\"context\": context, \"question\": q, \"stop\": [\"\\n\\n\"]})\n        end = time.time()\n\n        power_end = nvmlDeviceGetPowerUsage(handle) / 1000\n\n        # Approximate average power during inference\n        avg_power = (power_start + power_end) / 2\n        inference_time = end - start\n\n        print(f\"Q: {q}\")\n        print(f\"Output: {output}\")\n        print(f\"Inference Time: {inference_time:.4f} s | Avg Power: {avg_power:.2f} W\")\n        print(\"-\" * 50)\n\n        times.append(inference_time)\n        powers.append(avg_power)\n\n    avg_time = sum(times) / len(times)\n    avg_power = sum(powers) / len(powers)\n    efficiency_score = 1 / (avg_time * avg_power)\n\n    print(f\"\\nâœ… {model_name} Summary:\")\n    print(f\"Avg Time: {avg_time:.4f}s | Avg Power: {avg_power:.2f}W\")\n    print(f\"Efficiency Score: {efficiency_score:.5f}\\n\")\n\n    return {\n        \"model\": model_name,\n        \"avg_time\": avg_time,\n        \"avg_power\": avg_power,\n        \"efficiency_score\": efficiency_score\n    }\n\n# Run for both models (replace llm_chain_x with yours)\nresult1 = benchmark_model(llm_chain, \"Mistral-7B (QLoRA)\")\nnvmlShutdown()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}